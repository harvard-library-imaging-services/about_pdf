---
title: "About PDFs"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  slidy_presentation: 
    incremental: yes
    keep_md: yes
    css: "w3c-slidy.css"
    highlight: tango
  ioslides_presentation: 
    incremental: yes
    keep_md: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)


rm(list = ls()) # clear env vars

pkgs.inst <- as.data.frame(installed.packages(noCache = TRUE)) # list of installed R packages

pkgs.load <- c( # default list of packages to load
  "readr",
  "pandoc",
  "esquisse", # GUI ggplot 
  "vroom", # loads data fast
  "tidylog",
  "glue", # join strings neatly
  "tsibble", # time series data
  "tidytext", # pull apart text data, count elements
  "dplyr",
  "stats",
  "ggplot2",
  "scales",
  "RColorBrewer",
  "janitor", # clean-up messy col names janitor::clean_names()
  "lubridate",
  "htmlTable",
  "utf8",
  "RCurl",
  "tidyr",
  "xtable",
  "tidyverse",
  "jsonlite",
  # "Rtools",
  "formattable"
)
#
idx <- pkgs.load %in% pkgs.inst$Package == FALSE # index of packages that need to be installed
# pkgs.load[idx]
if(sum(idx) > 0){install.packages(pkgs.load[idx],dependencies = TRUE)} # if at least one package needs installing, run.
lapply(pkgs.load, require, character.only = TRUE) # require packages be loaded into current env
##
timezone <- "US/Eastern" #Set timezone # set TZ
if(is.na(Sys.timezone()) == TRUE){
  Sys.setenv(TZ=timezone)
}
##
os <- .Platform$OS.type
os <- Sys.info()[[1]][1] #windows linux # identify OS
#
```

```{r load, include=FALSE}

if(os == "Windows"){
  PDF_PRONOM_FileFormatReport <- read_csv("P:/R/data/PDF_PRONOM_FileFormatReport.csv")
} else {
  PDF_PRONOM_FileFormatReport <- read_csv("~/pCloud Drive/R/data/PDF_PRONOM_FileFormatReport.csv")
  }

names(PDF_PRONOM_FileFormatReport)

PDF <- PDF_PRONOM_FileFormatReport %>%
  filter(grepl("^Adobe",`Format Name`) == FALSE) %>%
  select("Format Name","Format Version","Extension","PUID")

# tbl.pdf <- print(xtable(PDF,auto = TRUE),type = "html",hline.after = TRUE,scalebox = TRUE)
tbl.pdf <- print(xtable(PDF),type = "html")

```

## 31 flavors, at least

`r tbl.pdf`

## Four types

* "True", digitally created PDF
* "Image-only" PDF
* Searchable, image-based PDF
* Hybrid (image & character description) PDF

## True, perfect PDFs

Given a choice, <mark>this is the PDF you want</mark>.

The text is encoded descriptively: *This font, at this size, should be rendered in this specific location on the page*, or *canvas*. The font is described as a shape at a location, and therefore can be scaled to any size output without degradation.

<script src="https://gist.github.com/euhmeuh/61fd1beebf6d4fd5692431ed8ee1b892.js"></script>

<mark>Because each character is explicitly recorded, searches are run against a perfect index.</mark>

## "Image-only" PDFs

*Image-only* PDFs\* are so different from *true*, *perfect* PDFs, I wish they were called something else.

<mark>An *image-only* PDF is just a sequence of raster images--grids of color and tone values.</mark>

###### * [PDF/R-1 (Raster image transport and storage.) Based on PDF 1.4-1.7 (ISO 32000-1)](https://www.loc.gov/preservation/digital/formats/fdd/fdd000493.shtml)

## "Image-only" PDFs, shortcomings

* These PDFs may include ***images of text***, but the text <mark>cannot be searched</mark>. Again, the PDF is only a sequence of images--grids of color and tone values.

* These PDFs include a series of **big FAT image files**, and are therefore, <mark>too large to open and navigate easily</mark>. 

## Searchable, image-based PDFs

These PDFs are also a sequence of images, but include a hidden layer of searchable text that is always imperfect, having been created by OCR software that worked to identify characters and words by analyzing the page-images.

## Searchable, image-based PDFs, shortcomings

* Like *image-only* PDFs, these files are often <mark>too large for users to open and navigate easily</mark>.

Example: [Cowen, Wilson Walker, et al. Melville's Marginalia.1965.](https://id.lib.harvard.edu/alma/990033679150203941/catalog)

  > <small>[V.1 INTRODUCTION. BIBLIOGRAPHIES. MARGINALIA (ALGER TO BALZAC)](https://nrs.harvard.edu/URN-3:HUL.ARCH:100557006) [ **4.07GB** ]</small>

* The OCR used to identify page-image <mark>text is error-prone</mark>. Pages typeset before computers, discolored pages, pages with schmutz, marginalia, or elaborate layouts--all of these characteristics degrade OCR accuracy, often dramatically.


## Hybrid (image & character description) PDF

Image-based PDFs with OCR-generated text can be converted to a hybrid of *true*, *perfect* and *image-based*. The software will look for OCR-generated text that the software has assigned a high confidence score, indicating it has likely identified the fonts and characters correctly, and it will throw away the page-image source and replace the image data with a described font and layout.

A single hybrid page may include encoded text that replaces part of the image, and page-image fragments for zones where the OCR confidence scores are low.

## Hybrid PDF, shortcomings

* This technique reduces the PDF size (by replacing fat image data with lean character descriptions), but it is <mark>unreliable</mark> and produces <mark>ugly</mark>, odd renderings of pages.

* Because the software discards image data that it replaces with character descriptions, you <mark>cannot recover from errors</mark> without access to the originally scanned page-images.

* Many fonts are licensed, so if Adobe cannot substitute a recognized character with the correct font, Adobe will substitute another that approximates the original.

## How does one create a *true*, *perfect* PDF from a scanned text?

There is no reliable, automated method. To reliably turn digitized book-pages into accurate searchable text, re-keying is required. Typically, at least three typists re-key the text and software compares the three results, using discrepancies to identify errors.

## How does one create an image-based PDF with a perfect index for searching?

OCR the pages, and use special software to review potential errors and correct each one manually.

## What kind of PDFs does Imaging Services make?

Assuming a volume has text, and assuming Imaging Services has OCR software capable of identifying the language, and character set, Imaging Services creates image-based PDFs with imperfect indexes for searching.

## *END*

>Link to this presentation: [https://harvard-library-imaging-services.github.io/about_pdf/](https://harvard-library-imaging-services.github.io/about_pdf/)
>
> [Presentation source file](aboutPDFs.Rmd)






```{r RUN_MANUALLY, include=FALSE, eval=TRUE}

# browseURL("https://harvard-library-imaging-services.github.io/about_pdf/")

file.copy(from = "aboutPDFs.html", to = "index.html",overwrite = TRUE)

system("git status")
system("git add --all")
system("git commit -m \"updates\"")
system("git push origin main")

```
