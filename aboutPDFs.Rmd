---
title: "About PDFs"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  slidy_presentation: 
    incremental: yes
    keep_md: yes
    css: "w3c-slidy.css"
    font_adjustment: +4
    footer: "https://harvard-library-imaging-services.github.io/about_pdf/"
  ioslides_presentation:
    incremental: yes
    keep_md: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)


rm(list = ls()) # clear env vars

pkgs.inst <- as.data.frame(installed.packages(noCache = TRUE)) # list of installed R packages

pkgs.load <- c( # default list of packages to load
  "readr",
  "pandoc",
  "esquisse", # GUI ggplot 
  "vroom", # loads data fast
  "tidylog",
  "glue", # join strings neatly
  "tsibble", # time series data
  "tidytext", # pull apart text data, count elements
  "dplyr",
  "stats",
  "ggplot2",
  "scales",
  "RColorBrewer",
  "janitor", # clean-up messy col names janitor::clean_names()
  "lubridate",
  "htmlTable",
  "utf8",
  "RCurl",
  "tidyr",
  "xtable",
  "tidyverse",
  "jsonlite",
  "xaringan",
  # "Rtools",
  "formattable"
)
#
idx <- pkgs.load %in% pkgs.inst$Package == FALSE # index of packages that need to be installed
# pkgs.load[idx]
if(sum(idx) > 0){install.packages(pkgs.load[idx],dependencies = TRUE)} # if at least one package needs installing, run.
lapply(pkgs.load, require, character.only = TRUE) # require packages be loaded into current env
##
timezone <- "US/Eastern" #Set timezone # set TZ
if(is.na(Sys.timezone()) == TRUE){
  Sys.setenv(TZ=timezone)
}
##
os <- .Platform$OS.type
os <- Sys.info()[[1]][1] #windows linux # identify OS
#
```

```{r load, include=FALSE}

if(os == "Windows"){
  PDF_PRONOM_FileFormatReport <- read_csv("P:/R/data/PDF_PRONOM_FileFormatReport.csv")
} else if(os == "Linux" &
          Sys.info()[[4]][1] == "penguin") {
  PDF_PRONOM_FileFormatReport <- read_csv("/home/comstock/pCloudDrive/R/data/PDF_PRONOM_FileFormatReport.csv")
  } else if(os == "unix"){
  PDF_PRONOM_FileFormatReport <- read_csv("~/pCloud Drive/R/data/PDF_PRONOM_FileFormatReport.csv")
  }

names(PDF_PRONOM_FileFormatReport)

PDF <- PDF_PRONOM_FileFormatReport %>%
  filter(grepl("^Adobe",`Format Name`) == FALSE) %>%
  select("Format Name","Format Version")#,"PUID")

# tbl.pdf <- print(xtable(PDF,auto = TRUE),type = "html",hline.after = TRUE,scalebox = TRUE)
tbl.pdf <- print(xtable(PDF),type = "html",include.rownames = FALSE)

```

## Our plea for a new *best practice*

When digitizing library materials, <mark>we should avoid making PDFs for preservation and access</mark>.

## Digitized Harvard theses & dissertations

When digitizing paper theses...<br /><br /><mark>Why are we making PDFs instead of the page-turned objects we typically deliver via the Page Delivery Service (PDS)?</mark>

- Because, due to rights restrictions, we cannot make the digitized copies accessible online, and therefore we must deliver to patrons a format they can navigate on their own machines.

  * The PDF Acrobat Reader is a patron's portable page-turning application.

* How do we deliver PDFs to patrons?

* > By secretly making the PDF link live, briefly, so the patron can download a copy.
* > By downloading all the image files, and creating a PDF for the patron.


## So, what's the problem? Why shouldn't we make PDF's from scanned theses.

* Too fat. The PDFs are huge--so huge, in many cases, one can imagine they'll be difficult to open and navigate for many patrons.
* Too vulnerable to Acrobat's destructive image processing.
* Too hard to migrate to a new format.
* Too hard to decompose into page-images for computational analysis.

## What's the alternative?

* Make the same kind of page-turned digital resources we make for other digitized collections.
* Generate PDFs on-the-fly for patrons, on-demand.

## *"I don't understand, I use PDFs all the time. What's your problem?"*


## A PDF isn't what you think it is because it isn't one thing

It is hard to talk about PDFs as if a "PDF" is a single thing,<br />where one PDF is reliably similar, in most respects, to any other PDF file.

## 31 flavors, at least

`r tbl.pdf`

## Three different builds

1. "True", digitally created PDF
2. "Image-only" PDF
3. Searchable, image-based PDF
<!-- 5. Hybrid (image & character description) PDF -->

## True, perfect PDFs

Given a choice, <mark>this is the PDF you want</mark>.

The text is encoded descriptively:<br />*This font, at this size, should be rendered in this specific location on the page*.<br /><br />
The font is described as a shape at a location, and therefore can be scaled to any size output without degradation.

<script src="https://gist.github.com/euhmeuh/61fd1beebf6d4fd5692431ed8ee1b892.js"></script>

<mark>Because each character is explicitly recorded, text searches are run against a perfect index.</mark>

## "Image-only" PDFs

*Image-only* PDFs\* are so different from *true*, *perfect* PDFs,<br />I wish they were called something else.

<mark>An *image-only* PDF is just a sequence of raster images--grids of color and tone values.</mark>

###### * [PDF/R-1 (Raster image transport and storage.) Based on PDF 1.4-1.7 (ISO 32000-1)](https://www.loc.gov/preservation/digital/formats/fdd/fdd000493.shtml)

## "Image-only" PDFs, shortcomings

* These PDFs may include ***images of text***, but the text <mark>cannot be searched</mark>. Again, the PDF is only a sequence of images--grids of color and tone values.

* These PDFs include a series of **big FAT image files**, and are therefore, <mark>too large to open and navigate easily</mark>. 

## Searchable, image-based PDFs

These PDFs too contain a sequence of images, but also include a hidden layer of searchable text that is always imperfect, having been created by OCR software that worked to identify characters and words by analyzing the page-images.

## Searchable, image-based PDFs, shortcomings

* Like *image-only* PDFs, these files are often <mark>too large for users to open and navigate easily</mark>.

Example: [Cowen, Wilson Walker, et al. Melville's Marginalia.1965.](https://id.lib.harvard.edu/alma/990033679150203941/catalog)

  > <small>[V.1 INTRODUCTION. BIBLIOGRAPHIES. MARGINALIA (ALGER TO BALZAC)](https://nrs.harvard.edu/URN-3:HUL.ARCH:100557006) [ **4.07GB** ]</small>

* The OCR used to identify page-image <mark>text is error-prone</mark>. Pages typeset before computers, discolored pages, pages with schmutz, marginalia, or elaborate layouts--all of these characteristics degrade OCR accuracy, often dramatically.

<!-- ## Hybrid (image & character description) PDF -->

<!-- Image-based PDFs with OCR-generated text can be converted to a hybrid of *true*, *perfect* and *image-based*. The software will look for OCR-generated text that the software has assigned a high confidence score, indicating it has likely identified the fonts and characters correctly, and it will throw away the page-image source and replace the image data with a described font and layout. -->

<!-- A single hybrid page may include encoded text that replaces part of the image, and page-image fragments for zones where the OCR confidence scores are low. -->

<!-- ## Hybrid PDF, shortcomings -->

<!-- * This technique reduces the PDF size (by replacing fat image data with lean character descriptions), but it is <mark>unreliable</mark> and produces <mark>ugly</mark>, odd renderings of pages. -->

<!-- * Because the software discards image data that it replaces with character descriptions, you <mark>cannot recover from errors</mark> without access to the originally scanned page-images. -->

<!-- * Many fonts are licensed, so if Adobe cannot substitute a recognized character with the correct font, Adobe will substitute another that approximates the original. -->

## How does one create a *true*, *perfect* PDF from a scanned text?

There is no reliable, automated method.<br /><br />

* To reliably turn digitized book-pages into accurate searchable text, re-keying is required. Typically, at least three typists re-key the text and software compares the three results, using discrepancies to identify errors.

* Or, OCR the pages, and use special software to review potential errors and correct each one manually.

<!-- ## How does one create an image-based PDF with a perfect index for searching? -->

<!-- OCR the pages, and use special software to review potential errors and correct each one manually. -->

## What kind of PDFs does Imaging Services make?

Assuming a volume has text, and assuming Imaging Services has<br />OCR software capable of processing the languages, and character set,<br /><mark>Imaging Services creates image-based PDFs with imperfect indexes for searching</mark>.

<!-- ## Notes from the Assistive Technology Center -->

<!-- * ATC staff take the TIFF images the library provides and processes them to produce searchable text. -->
<!-- * ABBYY is used to correct errors -->
<!-- * Specialized software and outsourced services are used in special cases (e.g., OCR or re-keying Arabic texts) -->
<!-- * MS Word or PDF files are delivered to students, with MS Word being the default. -->
<!-- 	* Students prefer MS WORD because they change fonts and  leading. -->
<!-- 	* Text to braille software takes MS WORD as input, not PDF. -->
<!-- * The University is providing ATC offices with licenses to SAAS, [SensusAccess](https://www.sensusaccess.com/) -->
<!-- * ATC isn't planning to correct all texts -->
<!-- 	* High quality results are typically sufficient for most students.. -->
<!-- * Graduate student needs have overwhelmed ATC -->
<!-- 	* One student this year needed 600 books scanned, hundreds of thousands of pages -->
<!-- * Grad students with disabilities will now be provided with a 20 hour per week research assistant that ATC will train to support the student. -->

## *~~ FIN ~~*

### Related links

#### &bull; [Test instance of new *Mirador* page-turner](https://viewer.lib.harvard.edu/)

> &bull; Check out the [updated *Download PDF* feature](https://viewer.lib.harvard.edu/example/mps/urn-3:KSG.LIBR:40505153?manifestVersion=3).
>
> &bull; [Documentation](https://ask.library.harvard.edu/faq/392399)









```{r RUN_MANUALLY, include=FALSE, eval=TRUE}

# browseURL("https://harvard-library-imaging-services.github.io/about_pdf/")

file.copy(from = "aboutPDFs.html", to = "index.html",overwrite = TRUE)

# system("git status")
# system("git add --all")
# system("git commit -m \"updates\"")
# system("git push origin main")

```
